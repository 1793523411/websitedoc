# 综合能力提升(下)

## 框架到底用了哪些设计模式？

> 设计模式（Design Pattern）是对软件设计中普遍存在（反复出现）的各种问题所提出的解决方案。设计模式并不直接用来完成代码的编写，而是描述在各种不同情况下，要怎么解决问题的一种方案。

从这个定义不难看出，设计模式就是一套抽象的理论，属于编程知识中的“道”而非“术”，对于理论的学习我们最好的学习方式就是通过与实践结合来加深理解，所以接下来我们在分析设计模式相关概念的同时通过具体实例来加深对其理解

### 设计模式原则

设计模式其实是针对面向对象编程范式总结出来的解决方案，所以设计模式的原则都是围绕“类”和“接口”这两个概念来提出的，其中下面 6 个原则非常重要，因为这 6 个原则决定了设计模式的规范和标准。

**开闭原则**

开闭原则指的就是对扩展开放、对修改关闭。编写代码的时候不可避免地会碰到修改的情况，而遵循开闭原则就意味着当代码需要修改时，可以通过编写新的代码来扩展已有的代码，而不是直接修改已有代码本身。

下面的伪代码是一个常见的表单校验功能，校验内容包括用户名、密码、验证码，每个校验项都通过判断语句 if-else 来控制。

```js
function validate() {
    // 校验用户名
    if (!username) {
        ...
    } else {
        ...
    }
    // 校验密码
    if (!pswd){
        ...
    } else {
        ...
    }
    // 校验验证码
    if (!captcha) {
        ...
    } else {
        ...
    }
}
```

这么写看似没有问题，但其实可扩展性并不好，如果此时增加一个校验条件，就要修改 validate() 函数内容。

下面的伪代码遵循开闭原则，将校验规则抽取出来，实现共同的接口 IValidateHandler，同时将函数 validate() 改成 Validation 类，通过 addValidateHandler() 函数添加校验规则，通过 validate() 函数校验表单。这样，当有新的校验规则出现时，只要实现 IValidateHandler 接口并调用 addValidateHandler() 函数即可，不需要修改类 Validation 的代码。

```ts
class Validation {
    private validateHandlers: ValidateHandler[] = [];
    public addValidateHandler(handler: IValidateHandler) {
        this.validateHandlers.push(handler)
    }
    public validate() {
        for (let i = 0; i < this.validateHandlers.length; i++) {
            this.validateHandlers[i].validate();
        }
    }
}
interface IValidateHandler {
    validate(): boolean;
}
class UsernameValidateHandler implements IValidateHandler {
    public validate() {
      ...
    }
}
class PwdValidateHandler implements IValidateHandler {
    public validate() {
      ...
    }
}
class CaptchaValidateHandler implements IValidateHandler {
    public validate() {
      ...
    }
}
```

**里氏替换原则**

里氏替换原则是指在使用父类的地方可以用它的任意子类进行替换。里氏替换原则是对类的继承复用作出的要求，要求子类可以随时替换掉其父类，同时功能不被破坏，父类的方法仍然能被使用。

下面的代码就是一个违反里氏替换原则的例子，子类 Sparrow 重载了父类 Bird 的 getFood() 函数，但返回值发生了修改。那么如果使用 Bird 类实例的地方改成 Sparrow 类实例则会报错。

```js
class Bird {
  getFood() {
    return "虫子";
  }
}

class Sparrow extends Bird {
  getFood() {
    return ["虫子", "稻谷"];
  }
}
```

对于这种需要重载的类，正确的做法应该是让子类和父类共同实现一个抽象类或接口。下面的代码就是实现了一个 IBird 接口来遵循里氏替换原则。

```ts
interface IBird {
  getFood(): string[];
}
class Bird implements IBird {
  getFood() {
    return ["虫子"];
  }
}

class Sparrow implements IBird {
  getFood() {
    return ["虫子", "稻谷"];
  }
}
```

**依赖倒置原则**

准确说应该是避免依赖倒置，好的依赖关系应该是类依赖于抽象接口，不应依赖于具体实现。这样设计的好处就是当依赖发生变化时，只需要传入对应的具体实例即可。

下面的示例代码中，类 Passenger 的构造函数需要传入一个 Bike 类实例，然后在 start() 函数中调用 Bike 实例的 run() 函数。此时类 Passenger 和类 Bike 的耦合非常紧，如果现在要支持一个 Car 类则需要修改 Passenger 代码。

```js
class Bike {
  run() {
    console.log('Bike run')
  }
}
class Passenger {
  construct(Bike: bike) {
    this.tool = bike
  }
  public start() {
    this.tool.run()
  }
}
```

如果遵循依赖倒置原则，可以声明一个接口 ITransportation，让 Passenger 类的构造函数改为 ITransportation 类型，从而做到 Passenger 类和 Bike 类解耦，这样当 Passenger 需要支持 Car 类的时候，只需要新增 Car 类即可。

```ts
interface ITransportation {
  run(): void;
}
class Bike implements ITransportation {
  run() {
    console.log("Bike run");
  }
}
class Car implements ITransportation {
  run() {
    console.log("Car run");
  }
}
class Passenger {
  construct(ITransportation: transportation) {
    this.tool = transportation;
  }
  public start() {
    this.tool.run();
  }
}
```

**接口隔离原则**

不应该依赖它不需要的接口，也就是说一个类对另一个类的依赖应该建立在最小的接口上。目的就是为了降低代码之间的耦合性，方便后续代码修改。

下面就是一个违反接口隔离原则的反例，类 Dog 和类 Bird 都继承了接口 IAnimal，但是 Bird 类并没有 swim 函数，只能实现一个空函数 swim()。

```ts
interface IAnimal {
  eat(): void
  swim(): void
}
class Dog implements IAnimal {
  eat() {
    ...
  }
  swim() {
    ...
  }
}
class Bird implements IAnimal {
  eat() {
    ...
  }
  swim() {
    // do nothing
  }
}
```

**迪米特原则**

一个类对于其他类知道得越少越好，就是说一个对象应当对其他对象尽可能少的了解。这一条原则要求任何一个对象或者方法只能调用该对象本身和内部创建的对象实例，如果要调用外部的对象，只能通过参数的形式传递进来。这一点和纯函数的思想相似。

下面的类 Store 就违反了迪米特原则，类内部使用了全局变量。

```JS
class Store {
  set(key, value) {
    window.localStorage.setItem(key, value)
  }
}
```

一种改造方式就是在初始化的时候将 window.localstorage 作为参数传递给 Store 实例。

```JS
class Store {
  construct(s) {
    this._store = s
  }
  set(key, value) {
    this._store.setItem(key, value)
  }
}
new Store(window.localstorage)
```

**单一职责原则**

应该有且仅有一个原因引起类的变更。这个原则很好理解，一个类代码量越多，功能就越复杂，维护成本也就越高。遵循单一职责原则可以有效地控制类的复杂度。

像下面这种情形经常在项目中看到，一个公共类聚集了很多不相关的函数，这就违反了单一职责原则。

```JS
class Util {
  static toTime(date) {
    ...
  }
  static formatString(str) {
    ...
  }
  static encode(str) {
    ...
  }
}
```

了解了设计模式原则之后，下面再来看看具体的设计模式。

### 设计模式的分类

经典的设计模式有 3 大类，共 23 种，包括创建型、结构型和行为型。

**创建型**

创建型模式的主要关注点是“如何创建和使用对象”，这些模式的核心特点就是将对象的创建与使用进行分离，从而降低系统的耦合度。使用者不需要关注对象的创建细节，对象的创建由相关的类来完成。

具体包括下面几种模式：

- 抽象工厂模，提供一个超级工厂类来创建其他工厂类，然后通过工厂类创建类实例；
- 生成器模式(建造者模式)，将一个复杂对象分解成多个相对简单的部分，然后根据不同需要分别创建它们，最后构建成该复杂对象；
- 工厂方法模式，定义一个用于创建生成类的工厂类，由调用者提供的参数决定生成什么类实例；
- 原型模式，将一个对象作为原型，通过对其进行克隆创建新的实例；
- 单例模式，生成一个全局唯一的实例，同时提供访问这个实例的函数。

下面的代码示例是 Vue.js 源码中使用单例模式的例子。其中，构造了一个唯一的数组 \_installedPlugins 来保存插件，并同时提供了 Vue.use() 函数来新增插件。

```js
// src/core/global-api/use.js
export function initUse (Vue: GlobalAPI) {
  Vue.use = function (plugin: Function | Object) {
    const installedPlugins = (this._installedPlugins || (this._installedPlugins = []))
    if (installedPlugins.indexOf(plugin) > -1) {
      return this
    }
    ......
  }
}
```

下面的代码中，cloneVNode() 函数通过已有 vnode 实例来克隆新的实例，用到了原型模式。

```js
// src/core/vdom/vnode.js
export function cloneVNode(vnode: VNode): VNode {
  const cloned = new VNode(
    vnode.tag,
    vnode.data,
    // #7975
    // clone children array to avoid mutating original in case of cloning
    // a child.
    vnode.children && vnode.children.slice(),
    vnode.text,
    vnode.elm,
    vnode.context,
    vnode.componentOptions,
    vnode.asyncFactory
  );
  cloned.ns = vnode.ns;
  cloned.isStatic = vnode.isStatic;
  cloned.key = vnode.key;
  cloned.isComment = vnode.isComment;
  cloned.fnContext = vnode.fnContext;
  cloned.fnOptions = vnode.fnOptions;
  cloned.fnScopeId = vnode.fnScopeId;
  cloned.asyncMeta = vnode.asyncMeta;
  cloned.isCloned = true;
  return cloned;
}
```

**结构型**

结构型模式描述如何将类或对象组合在一起形成更大的结构。它分为类结构型模式和对象结构型模式，类结构型模式采用继承机制来组织接口和类，对象结构型模式釆用组合或聚合来生成新的对象。

具体包括下面几种模式：

- 适配器模式，将一个类的接口转换成另一个类的接口，使得原本由于接口不兼容而不能一起工作的类能一起工作；
- 桥接模式，将抽象与实现分离，使它们可以独立变化，它是用组合关系代替继承关系来实现的，从而降低了抽象和实现这两个可变维度的耦合度；
- 组合模式，将对象组合成树状层次结构，使用户对单个对象和组合对象具有一致的访问性；
- 装饰器模式，动态地给对象增加一些职责，即增加其额外的功能；
- 外观模式，为多个复杂的子系统提供一个统一的对外接口，使这些子系统更加容易被访问；
- 享元模式，运用共享技术来有效地支持大量细粒度对象的复用；
- 代理模式，为某对象提供一种代理以控制对该对象的访问，即客户端通过代理间接地访问该对象，从而限制、增强或修改该对象的一些特性。

Vue.js 在判断浏览器支持 Proxy 的情况下会使用代理模式，下面是具体源码：

```js
// src/core/instance/proxy.js
initProxy = function initProxy(vm) {
  if (hasProxy) {
    // determine which proxy handler to use
    const options = vm.$options;
    const handlers =
      options.render && options.render._withStripped ? getHandler : hasHandler;
    vm._renderProxy = new Proxy(vm, handlers);
  } else {
    vm._renderProxy = vm;
  }
};
```

Vue 的 Dep 类则应用了代理模式，调用 notify() 函数来通知 subs 数组中的 Watcher 实例。

```js
// src/core/observer/dep.js
export default class Dep {
  static target: ?Watcher;
  id: number;
  subs: Array<Watcher>;

  constructor() {
    this.id = uid++;
    this.subs = [];
  }

  addSub(sub: Watcher) {
    this.subs.push(sub);
  }

  removeSub(sub: Watcher) {
    remove(this.subs, sub);
  }

  depend() {
    if (Dep.target) {
      Dep.target.addDep(this);
    }
  }

  notify() {
    // stabilize the subscriber list first
    const subs = this.subs.slice();
    if (process.env.NODE_ENV !== "production" && !config.async) {
      // subs aren't sorted in scheduler if not running async
      // we need to sort them now to make sure they fire in correct
      // order
      subs.sort((a, b) => a.id - b.id);
    }
    for (let i = 0, l = subs.length; i < l; i++) {
      subs[i].update();
    }
  }
}
```

**行为型**

行为型模式用于描述程序在运行时复杂的流程控制，即描述多个类或对象之间怎样相互协作共同完成单个对象无法单独完成的任务，它涉及算法与对象间职责的分配。

行为型模式分为类行为模式和对象行为模式，类的行为模式采用继承机制在子类和父类之间分配行为，对象行为模式采用多态等方式来分配子类和父类的职责。

具体包括下面几种模式：

- 责任链模式，把请求从链中的一个对象传到下一个对象，直到请求被响应为止，通过这种方式去除对象之间的耦合；
- 命令模式，将一个请求封装为一个对象，使发出请求的责任和执行请求的责任分割开；
- 策略模式，定义了一系列算法，并将每个算法封装起来，使它们可以相互替换，且算法的改变不会影响使用算法的用户；
- 解释器模式，提供如何定义语言的文法，以及对语言句子的解释方法，即解释器；
- 迭代器模式，提供一种方法来顺序访问聚合对象中的一系列数据，而不暴露聚合对象的内部表示；
- 中介者模式，定义一个中介对象来简化原有对象之间的交互关系，降低系统中对象间的耦合度，使原有对象之间不必相互了解；
- 备忘录模式，在不破坏封装性的前提下，获取并保存一个对象的内部状态，以便以后恢复它；
- 观察者模式，多个对象间存在一对多关系，当一个对象发生改变时，把这种改变通知给其他多个对象，从而影响其他对象的行为；
- 状态模式，类的行为基于状态对象而改变；
- 访问者模式，在不改变集合元素的前提下，为一个集合中的每个元素提供多种访问方式，即每个元素有多个访问者对象访问；
- 模板方法模式，定义一个操作中的算法骨架，将算法的一些步骤延迟到子类中，使得子类在可以不改变该算法结构的情况下重定义该算法的某些特定步骤。

下面是 Vue.js 中使用状态对象 renderContext 的部分源码：

```js
// src/core/instance/render.js
export function initRender (vm: Component) {
  vm._vnode = null // the root of the child tree
  vm._staticTrees = null // v-once cached trees
  const options = vm.$options
  const parentVnode = vm.$vnode = options._parentVnode // the placeholder node in parent tree
  const renderContext = parentVnode && parentVnode.context
  vm.$slots = resolveSlots(options._renderChildren, renderContext)
  vm.$scopedSlots = emptyObject
  // bind the createElement fn to this instance
  // so that we get proper render context inside it.
  // args order: tag, data, children, normalizationType, alwaysNormalize
  // internal version is used by render functions compiled from templates
  ......
}
```

Vue.js 中通过 Object.defineProperty 劫持再发送消息则属于观察者模式。

```js
// src/core/observer/index.js
Object.defineProperty(obj, key, {
  enumerable: true,
  configurable: true,
  get: function reactiveGetter () {
    ......
  },
  set: function reactiveSetter (newVal) {
    const value = getter ? getter.call(obj) : val
    /* eslint-disable no-self-compare */
    if (newVal === value || (newVal !== newVal && value !== value)) {
      return
    }
    /* eslint-enable no-self-compare */
    if (process.env.NODE_ENV !== 'production' && customSetter) {
      customSetter()
    }
    // #7981: for accessor properties without setter
    if (getter && !setter) return
    if (setter) {
      setter.call(obj, newVal)
    } else {
      val = newVal
    }
    childOb = !shallow && observe(newVal)
    dep.notify()
  }
})
```

## 前端热点技术之 Serverless

严格意义上来说，Serverless 并不属于前端技术，但对于那些想提升自己知识广度，想往全栈工程师方向发展的前端工程师而言，是一个非常高效的工具。而对于那些只想专注于前端领域的工程师而言，了解 Serverless 背后的思想，对提升开发思维也会有一定的帮助。

### 什么是 Serverless

Serverless 是由“Server”和“less”两个单词组合而成，翻译成中文就是“无服务器”的意思，所谓无服务器并非脱离服务器的 Web 离线应用，也不是说前端页面绕过服务端直接读写数据库，而是开发者不用再考虑服务器环境搭建和维护等问题，只需要专注于开发即可。也就是说 Serverless 不是语言或框架，而是一种软件的部署方式。传统的应用需要部署在服务器或虚拟机上，安装运行环境之后以进程的方式启动，而使用 Serverless 则可以省略这个过程，直接使用云服务厂商提供的运行环境。

### Serverless 从何而来

Serverless 并不是一个全新的产物，而是一种构建和管理基于微服务架构的完整流程，允许在服务部署级别而不是在服务器部署级别来管理你的应用部署。与传统架构的不同之处在于，它完全由云厂商管理，由事件触发，以无状态的方式运行（可能只存在于一次调用的过程中）在容器内。

### Serverless 的组成

Serverless 架构由两部分组成，即 FaaS 和 BaaS。

FaaS（Function-as-a-Service）函数即服务，一个函数就是一个服务，函数可以由任何语言编写，除此之外不需要关心任何运维细节，比如计算资源、弹性扩容，而且还可以按量计费，且支持事件驱动。

BaaS（Backend-as-a-Service）后端即服务，集成了许多中间件技术，比如数据即服务（数据库服务）、缓存、网关等。

### Serverless 的特点

了解完 Serverless 的基础概念，我们再来看看它有哪些特点。

**免维护**

Serverless 不仅提供了运行代码的环境，还能自动实现负载均衡、弹性伸缩这类高级功能，极大地降低了服务搭建的复杂性，有效提升开发和迭代的速度。

**费用**

如果只考虑 FaaS，那么费用是比较便宜的。

以阿里云的函数计算为例，费用包括调用次数、执行时间、公网流量 3 个因素。调用次数和执行时间都有免费额度，即使超过，单次/每秒的费用也非常低，这种按需收费的方式就避免了资源的浪费。

流量费用则稍贵，达到 0.8 元/GB，而且没有免费额度，所以对于通信数据量比较大的场景还是要慎重使用。

![](https://s0.lgstatic.com/i/image/M00/4D/DA/Ciqc1F9bVNSABY8aAADMDBAJigk871.png)

**深度绑定**

通常使用某个云厂商的 Serverless 产品时，可能会包括多种产品，如函数计算、对象存储、数据库等，而这些产品和云厂商又深度绑定，所以如果要进行迁移，成本相对于部署在服务器而言会增加很多。

**运行时长限制**

通常云厂商对于 Serverless 中的函数执行时间是有限制的，如阿里云的函数计算产品，最大执行时长为 10 分钟，如果执行长时间任务，还需要单独申请调整时长上限，或者自行将超时函数拆分成粒度更小的函数，但是这种方式会增加一定的开发成本。

**冷启动**

由于函数是按需执行的，首次执行时会创建运行容器，一般这个创建环境的时间在几百毫秒，在延迟敏感的业务场景下需要进行优化，比如定时触发函数或者设置预留实例。

### Serverless 的应用场景

以阿里云的函数计算为例，可以分为两类：事件函数和 HTTP 函数。

- 事件函数。事件函数的执行方式有两种，一种是通过 SDK 提供的 API 函数调用它，基于此可以进行一些轻量计算操作，比如对图片进行压缩、格式转换，又或者执行一些 AI 训练任务；另一种是通过配置时间和间隔，让其自动执行，一些常见的自动执行场景包括文件备份、数据统计等。

- HTTP 函数。每一个 HTTP 函数都有特定的域名来供外部访问，当这个域名被访问时，函数将会被创建并执行。可以使用 HTTP 函数为前后端分离架构的 Web 应用提供后端数据支撑，比如提供获取天气 API 查看实时天气，或者提供 API 来读写数据库。

### Serverless 实例

下面来分析讲解一个使用阿里云函数计算来实现代码自动部署的例子。函数要实现的功能就是，当 GitHub 仓库中的某个分支有新的提交时，拉取最新代码并编译，然后将编译生成的代码部署到 OSS 存储的静态服务器上。

![](https://s0.lgstatic.com/i/image/M00/4D/E5/CgqCHl9bVLaATst6AADK7ETww2g973.png)

在这个例子中，两种函数都会用到。

首先是 HTTP 函数负责接收 GitHub 发出的 webhook 请求，当收到请求后使用内部模块调用一个事件函数，在这个事件函数中执行具体的操作。虽然理论上一个 HTTP 函数可以实现，但拆解成两个函数可以有效避免函数执行时间过长导致的 webhook 请求超时报错。

下面是 HTTP 函数源码：

```js
/**
 * ACCOUNT_ID 主账号ID
 * ACCESS_KEY_ID 访问 bucket 所需要的 key
 * ACCESS_KEY_SECRET 访问 bucket 所需要的 secret
 * REGION bucket 所在的 region
 * BUCKET 用于存储配置文件的 bucket
 */
const {
  ACCOUNT_ID,
  ACCESS_KEY_ID,
  ACCESS_KEY_SECRET,
  REGION,
  BUCKET,
} = process.env;

const FCClient = require("@alicloud/fc2");

const OSS = require("ali-oss");

const getRawBody = require("raw-body");

/**
 *
 * @param {string} filePath 函数计算配置文件路径
 */
const getOSSConfigFile = async (filePath) => {
  try {
    const client = new OSS({
      region: REGION,

      accessKeyId: ACCESS_KEY_ID,

      accessKeySecret: ACCESS_KEY_SECRET,

      bucket: BUCKET,
    });

    const result = await client.get(filePath);

    const content = result.content ? result.content.toString() : "{}";

    return JSON.parse(content);
  } catch (e) {
    console.error(e);

    return {};
  }
};

exports.handler = (req, resp) => {
  getRawBody(req, async (e, payload) => {
    const body = JSON.parse(payload);

    if (e) {
      console.error(e);
      resp.setStatusCode(400);
      resp.send("请求体解析失败");
      return;
    }
    let cfg;
    try {
      let config;
      config =
        (await getOSSConfigFile(`/config/${body.repository.name}.json`)) || {};
      cfg = config.action[body.action];
      if (!cfg) {
        console.error(config.action, body.action);
        throw Error("未找到对应仓库的配置信息.");
      }
    } catch (e) {
      console.error(e);
      resp.setStatusCode(500);
      resp.send(e.message);
      return;
    }

    if (cfg) {
      const client = new FCClient(ACCOUNT_ID, {
        accessKeyID: ACCESS_KEY_ID,

        accessKeySecret: ACCESS_KEY_SECRET,

        region: cfg.region,
      });

      client
        .invokeFunction(cfg.service, cfg.name, JSON.stringify(cfg))
        .catch(console.error);

      resp.send(
        `client.invokeFunction(${cfg.service}, ${cfg.name}, ${JSON.stringify(
          cfg
        )})`
      );
    }
  });
};
```

简单的实现方式就是解析 webhook 请求体内部的参数，获取仓库名和分支名传递给事件函数，但考虑可扩展性，对每个项目仓库使用了单独的配置文件。具体到代码中就是调用 getOSSConfigFile() 函数来从 OSS 存储上读取仓库相关的配置文件信息，然后通过 invokeFunction() 函数调用事件函数并将配置信息传递给事件函数。

这样的好处在于，之后要新增其他仓库或其他分支的时候，只需要新增一个配置文件就可以了。

**再来看看事件函数的入口函数实现**。

前面在讲 Serverless 函数冷启动问题的时候提到过，函数执行完成后会存活一段时间，在这段时间内再次调用会执行之前创建的函数，短时间内重复执行的话会因为已经存在目录导致拉取失败，所以创建了随机目录并修改工作目录到随机目录下以获取写权限。

然后再根据配置文件中的信息，按串行加载对应的执行模块并传入参数。

```js
const fs = require("fs");
/**
 *
 * @param {*} event
 *   {
 *     repo     仓库地址
 *     region   bucket 所在区域
 *     bucket   编译后部署的bucket
 *     command  编译命令
 *   }
 * @param {*} context
 * @param {*} callback
 */
exports.handler = async (event, context, callback) => {
  const { events } = Buffer.isBuffer(event)
    ? JSON.parse(event.toString())
    : event;
  let dir = Math.random()
    .toString(36)
    .substr(6);
  // 设置随机临时工作目录，避免容器未销毁的情况下，重复拉取仓库失败
  const workDir = `/tmp/${dir}`;
  // 为了保证后续流程能找到临时工作目录，设置为全局变量
  global.workDir = workDir;
  try {
    fs.mkdirSync(workDir);
  } catch (e) {
    console.error(e);
    return;
  }
  process.chdir(workDir);
  try {
    await events.reduce(async (acc, cur) => {
      await acc;
      return require(`./${cur.module}`)(cur);
    }, Promise.resolve());
    callback(null, `自动部署成功.`);
  } catch (e) {
    callback(e);
  }
};
```

具体有哪些模块呢？一般的部署过程主要包括 3 步：拉取仓库代码、安装依赖并构建、将生成的代码上传部署。

拉取代码对于手动操作而言很简单，一条 git clone 命令就搞定了，但在自动化实现的时候会碰到一些麻烦的细节问题。

首先身份认证问题。由于是私有仓库，所以只能通过密钥文件或账号密码的形式来认证访问权限。如果通过账号密码的形式登录，则要模拟键终端交互，这个相对而言实现成本较高，所以采用了配置 ssh key 的方式。具体是根据前面传入的配置信息找到私钥文件所在地址并下载到本地，但是因为权限问题，并不能直接保存到当前用户的 .ssh 目录下。

另一个问题是在首次进行 git clone 操作的时候，终端会出现一个是否添加 known hosts 的提示，在终端中操作的时候需要键盘输入 “Y” 或者 “N” 来继续后面的操作。这里可以通过一个选项本来关闭这个提示

具体实现参考下面的 shell 脚本。

```bash
#!/bin/sh
ID_RSA=/tmp/id_rsa
exec /usr/bin/ssh -o StrictHostKeyChecking=no -o GSSAPIAuthentication=no -i $ID_RSA "$@"
```

解决了比较麻烦的身份认证和终端交互问题之后，剩下的逻辑就比较简单了，执行 git clone 命令拉取仓库代码就行，为了加快速下载速度，可以通过设置 --depth 1 这个参数来指定只拉取最新提交的代码。

```js
const OSS = require("ali-oss");
const cp = require("child_process");
const { BUCKET, REGION, ACCESS_KEY_ID, ACCESS_KEY_SECRET } = process.env;
const shellFile = "ssh.sh";
/**
 *
 * @param {string} repoURL 代码仓库地址
 * @param {string} repoKey 访问代码仓库所需要的密钥文件路径
 * @param {string} branch  分支名称
 */
const downloadRepo = async (
  { repoURL, repoKey, branch = "master" },
  retryTimes = 0
) => {
  try {
    console.log(`Download repo ${repoURL}`);
    process.chdir(global.workDir);
    const client = new OSS({
      accessKeyId: ACCESS_KEY_ID,
      accessKeySecret: ACCESS_KEY_SECRET,
      region: REGION,
      bucket: BUCKET,
    });
    await client.get(repoKey, `./id_rsa`);
    await client.get(shellFile, `./${shellFile}`);
    cp.execSync(`chmod 0600 ./id_rsa`);
    cp.execSync(`chmod +x ./${shellFile}`);
    cp.execSync(
      `GIT_SSH="./${shellFile}" git clone -b ${branch} --depth 1 ${repoURL}`
    );
    console.log("downloaded");
  } catch (e) {
    console.error(e);
    if (retryTimes < 2) {
      downloadRepo({ repoURL, repoKey, branch }, retryTimes++);
    } else {
      throw e;
    }
  }
};
module.exports = downloadRepo;
```

安装依赖并构建这个步骤没有太多复杂的地方，通过子进程调用 yarn install --check-files 命令，然后执行 package.json 文件中配置的脚本任务即可。具体代码如下：

```js
const cp = require("child_process");

const install = (repoName, retryTimes = 0) => {
  try {
    console.log("Install dependencies.");
    cp.execSync(`yarn install --check-files`);
    console.log("Installed.");
    retryTimes = 0;
  } catch (e) {
    console.error(e.message);
    if (retryTimes < 2) {
      console.log("Retry install...");
      install(repoName, ++retryTimes);
    } else {
      throw e;
    }
  }
};
const build = (command, retryTimes = 0) => {
  try {
    console.log("Build code.");
    cp.execSync(`${command}`);
    console.log("Built.");
  } catch (e) {
    console.error(e.message);
    if (retryTimes < 2) {
      console.log("Retry build...");
      build(command, ++retryTimes);
    } else {
      throw e;
    }
  }
};

module.exports = ({ repoName, command }) => {
  const { workDir } = global;
  process.chdir(`${workDir}/${repoName}`);
  install(repoName);
  build(command);
};
```

最后上传部署可以根据不同的场景编写不同的模块，比如有的可能部署在 OSS 存储上，会需要调用 OSS 对应的 SDK 进行上传，有的可能部署在某台服务器上，需要通过 scp 命令来传输。

下面是一个部署到 OSS 存储的例子。

```js
const path = require("path");
const OSS = require("ali-oss");
// 遍历函数
const traverse = (dirPath, arr = []) => {
  var filesList = fs.readdirSync(dirPath);
  for (var i = 0; i < filesList.length; i++) {
    var fileObj = {};
    fileObj.name = path.join(dirPath, filesList[i]);
    var filePath = path.join(dirPath, filesList[i]);
    var stats = fs.statSync(filePath);
    if (stats.isDirectory()) {
      traverse(filePath, arr);
    } else {
      fileObj.type = path.extname(filesList[i]).substring(1);
      arr.push(fileObj);
    }
  }
  return arr;
};
/**
 *
 * @param {string} repoName
 *
 */
const deploy = (
  { dist = "", source, region, accessKeyId, accessKeySecret, bucket, repoName },
  retryTimes = 0
) =>
  new Promise(async (res) => {
    const { workDir } = global;
    console.log("Deploy.");
    try {
      const client = new OSS({
        region,
        accessKeyId,
        accessKeySecret,
        bucket,
      });
      process.chdir(`${workDir}/${repoName}`);
      const root = path.join(process.cwd(), source);
      let files = traverse(root, []);
      await Promise.all(
        files.map(({ name }, index) => {
          const remotePath = path.join(dist, name.replace(root + "/", ""));
          console.log(`[${index}] uploaded ${name} to ${remotePath}`);
          return client.put(remotePath, name);
        })
      );
      res();
      console.log("Deployed.");
    } catch (e) {
      console.error(e);
      if (retryTimes < 2) {
        console.log("Retry deploy.");
        deploy(
          { dist, source, region, accessKeyId, accessKeySecret, bucket },
          ++retryTimes
        );
      } else {
        throw e;
      }
    }
  });
module.exports = deploy;
```

由于未找到阿里云 OSS SDK 中上传目录的功能，所以只能通过深度遍历的方式来逐个将文件进行上传。考虑编译后生成地文件数量并不多，这里没有做并发数限制，而是将全部文件进行批量上传。

## 微前端与功能的可重用性

我们来思考一个问题，在日常开发中是怎么复用代码的？

- 复制粘贴。这是初级工程师最容易采用的方式，该方式虽然简单有效，但会给代码维护带来很多问题，比如增加了很多重复的代码，复用代码逻辑发生变动时需要处处修改。因此，这种违反 DRY（Don't Repeat Yourself）原则的方式应该尽量避免。

- 封装模块。稍有经验的工程师会考虑将代码逻辑封装成模块，然后通过引用模块的方式来复用，比如最常见的组件就是集成了视图操作的代码模块。这种方式解决了“复制粘贴”的可维护性问题，但如果将场景扩大，这种方式就行不通了，比如多个项目要使用同一个模块的时候。

- 打包成库。模块很好地解决了跨文件复用代码的问题，对于跨项目复用的情况可以通过打包成库的方式来解决，比如前端领域中会打包成库然后发布到 NPM 中，使用的时候再通过命令行工具来安装。

- 提供服务。库这种复用方式其实也有缺陷，首先库有特定的依赖，比如要在 React 项目使用基于 Vue 开发的树形组件，就必须把 Vue 也引进来，这样势必会增加项目体积和复杂度；其次库更多的是偏向功能的复用，而偏向业务的代码则很少用库来实现。如果使用微前端架构就可以按照业务拆分成微应用，然后再通过配置引用的方式来复用所需的微应用。

不过微前端最早被提出不是为了代码的复用，而是用来将项目进行拆分和解耦。

### 微前端概念

“微前端”一词最早于 2016 年底在 ThoughtWorks Technology Radar 中提出，它将后端的微服务概念扩展到了前端世界。微服务是服务端提出的一个有界上下文、松耦合的架构模式，具体是将应用的服务端拆分成更小的微服务，这些微服务都能独立运行，采用轻量级的通信方式（比如 HTTP ）。

微前端概念的提出可以借助下面的 Web 应用架构模式演变图来理解。

![](https://s0.lgstatic.com/i/image/M00/50/25/Ciqc1F9h5ZaAKe-1AACsAd0gjts226.png)

最原始的架构模式是单体 Web 应用，整个应用由一个团队来负责开发。

随着技术的发展，开发职责开始细分，一个项目的负责团队会分化成前端团队和后端团队，即出现了前后端分离的架构方式。

随着项目变得越来越复杂，先感受到压力的是后端，于是微服务的架构模式开始出现。

随着前端运行环境进一步提升，Web 应用的发展趋势越来越倾向于富应用，即在浏览器端集成更多的功能，前端层的代码量以及业务逻辑也开始快速增长，从而变得越来越难以维护。于是引入了微服务的架构思想，将网站或 Web 应用按照业务拆分成粒度更小的微应用，由独立的团队负责开发。

从图上可以看出，微前端、微服务这些架构模式的演变趋势就是不断地将逻辑进行拆分，从而降低项目复杂度，提升可维护性和可复用性。

### 微前端应用场景

从上面的演变过程可以看出，微前端架构比较适合大型的 Web 应用，常见的有以下 3 种形式。

- 公司内部的平台系统。这些系统之间存在一定的相关性，用户在使用过程中会涉及跨系统的操作，频繁地页面跳转或系统切换将导致操作效率低下。而且，在多个独立系统内部可能会开发一些重复度很高的功能，比如用户管理，这些重复的功能会导致开发成本和用户使用成本上升。
- 大型单页应用。这类应用的特点是系统体量较大，导致在日常调试开发的时候需要耗费较多时间，严重影响到开发体验和效率。而且随着业务上的功能升级，项目体积还会不断增大，如果项目要进行架构升级的话改造成本会很高。
- 对已有系统的兼容和扩展。比如一些项目使用的是老旧的技术，使用微前端之后，对于新功能的开发可以使用新的技术框架，这样避免了推翻重构，也避免了继续基于过时的技术进行开发。

### 微前端核心思想

微前端架构遵循下面 3 个核心思想。

1. 技术无关

前端看上去非常统一，不像服务端在语言上可选择性非常多（Java、Python、Go、PHP 等），但仍然在框架上存在分歧。微前端架构要求保留每个团队选择技术栈的权利，即不同微应用可以选择不同的技术框架来实现，当然也包括制定不同的发布周期和发布流程。

2. 环境独立

为了达到高度解耦的目的，每个微应用不应当共享运行时环境，即使所有微应用都使用了相同的框架，那么它们之间应该尽量避免依赖共享状态或全局变量。

为了避免微应用之间产生冲突，应该通过命名前缀等方式来对一些公共作用域进行隔离。

对于 CSS 隔离，比较容易产生冲突的是主应用与微应用，可以采用 CSS Module 或者命名空间的方式，在编写每个微应用时使用约定好的特定前缀，或者采用 postcss 插件，在打包时添加特定的前缀。

另一种隔离，不同于微应用之间的 CSS 方式是在每次新的微应用加载时，将前一个微应用的 link 和 style 进行卸载。

对于 JavaScript 隔离则会麻烦一些，比较好的做法是使用沙箱的方式来进行隔离。沙箱机制的核心是让局部的 JavaScript 运行时，对外部对象的访问和修改处在可控的范围内，即无论内部怎么运行，都不会影响外部的对象。可以通过 with 关键字和 window.Proxy 对象来实现浏览器端的沙箱。

需要注意的是，沙箱机制核心在于创建一个虚拟的运行环境，并不等同于创建独立的作用域。在独立作用域中会有污染全局变量的风险，比如在独立作用域修改了原生 API 将 Array.prototype.forEach = null，那么之后的所有代码创建的数组执行 forEach 时都会报错，而沙箱机制就能避免这种问题的产生。

这种沙箱机制不仅能保证微应用之间的独立性，还能保证主应用的稳定性，所以当某个微应用的 JavaScript 执行失败或尚未执行时，整个应用应该仍是可用的。

3. 原生优先

原生优先使用浏览器事件进行通信，而不要使用自封装的发布订阅系统。如果确实必须跨应用进行通信，尽量让通信内容和方式变得简单，这样能有效地减少微应用之间的公共依赖。

### 微前端架构模式

了解完微前端的基本原理之后再来看看具体是如何实现的。微前端架构按集成微应用的位置不同，主要可以分为 2 类：

- 在服务端集成微应用，比如通过 Nginx 代理转发；
- 在浏览器集成微应用，比如使用 Web Components 的自定义元素功能。

一些说法认为通过构建工具在编译的时候进行集成也属于微前端范畴，比如将微应用发布成独立的 npm 包，共同作为主应用的依赖项，构建生成一个供部署的 JS Bundle，但这种方式并不符合微前端的核心思想，也并不是主流的微前端实现方式，故不做深入讨论。

这一课时我们只讨论服务端集成和浏览器端集成的情况。

### 服务端集成

服务端集成常用的方式是通过反向代理，在服务端进行路由转发，即通过路径匹配将不同请求转发到对应的微应用。这种架构方式实现起来比较容易，改造的工作量也比较小，因为只是将不同的 Web 应用拼凑在一起，严格地说并不能算是一个完整的 Web 应用。当用户从一个微应用跳转到另一个微应用时，往往需要刷新页面重新加载资源。

这种代理转发的方式和直接跳转到对应的 Web 应用相比具有一个优势，那就是不同应用之间的通信问题变得简单了，因为在同一个域下，所以可以共享 localstorage、cookie 这些数据。譬如每个微应用都需要身份认证信息 token，那么只需要登录后将 token 信息写入 localstorage，后续所有的微应用就都可以使用了，不必再重新登录或者使用其他方式传递登录信息。

### 浏览器集成

浏览器集成也称运行时集成，常见的方式有以下 3 种。

- iframe。通过 iframe 的方式将不同的微应用集成到主应用中，实现成本低，但样式、兼容性方面存在一定问题，比如沙箱属性 sandbox 的某些值在 IE 下不支持。
- 前端路由。每个微应用暴露出渲染函数，主应用在启动时加载各个微应用的主模块，之后根据路由规则渲染相应的微应用。虽然实现方式比较灵活，但有一定的改造成本。
- Web Components。基于原生的自定义元素来加载不同微应用，借助 Shadow DOM 实现隔离，改造成本比较大。

这也是一种非常热门的集成方式，代表性的框架有 single-spa 以及基于它修改的乾坤

---

首先，微前端这种架构模式来源于微服务，目的在于对项目进行拆分和隔离，从而提高项目的可维护性和可复用性；

其次，微前端这种架构的核心思想有 3 点，技术无关、环境独立、原生优先，其中环境独立比较难以实现，需要借助一定的技术手段或代码规范；

最后，主流的微前端实现方式大致分为两类，在服务端集成或者在浏览器端集成，服务端集成一般通过代理转发方式实现；在浏览器端集成则实现方式较多，也有例如 single-spa 这类框架支持。
